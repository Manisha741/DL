{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentiment-training-test.data.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Register now for @scacompanies Introduction to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @CaptMarkKelly: Arizona needs an independen...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @CaptMarkKelly: Arizona needs an independen...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @arthur_affect: The bullshit \\image enhance...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @acampbell99: I’m hearing that an announcem...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Register now for @scacompanies Introduction to...  negative\n",
       "1  RT @CaptMarkKelly: Arizona needs an independen...   neutral\n",
       "2  RT @CaptMarkKelly: Arizona needs an independen...   neutral\n",
       "3  RT @arthur_affect: The bullshit \\image enhance...   neutral\n",
       "4  RT @acampbell99: I’m hearing that an announcem...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>register now for scacompanies introduction to ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt acampbell99 im hearing that an announcement...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>onaturalia lindseygrahamsc there is 1 h1b for ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you can see the last half century as focused o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data_science amp business_analytics course100 ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  register now for scacompanies introduction to ...  negative\n",
       "4  rt acampbell99 im hearing that an announcement...  positive\n",
       "6  onaturalia lindseygrahamsc there is 1 h1b for ...  positive\n",
       "8  you can see the last half century as focused o...  positive\n",
       "9  data_science amp business_analytics course100 ...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.sentiment != \"neutral\"]\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "# removing special chars\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "#\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>register now for scacompanies introduction to ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acampbell99 im hearing that an announcement o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>onaturalia lindseygrahamsc there is 1 h1b for ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you can see the last half century as focused o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data_science amp business_analytics course100 ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  register now for scacompanies introduction to ...  negative\n",
       "4   acampbell99 im hearing that an announcement o...  positive\n",
       "6  onaturalia lindseygrahamsc there is 1 h1b for ...  positive\n",
       "8  you can see the last half century as focused o...  positive\n",
       "9  data_science amp business_analytics course100 ...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[ data['sentiment'] == 'positive'].size)\n",
    "print(data[ data['sentiment'] == 'negative'].size)\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt','')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,  50, 121,   2, 122,  51,   6,  52,   1,\n",
       "         10,  13, 123,   5, 124, 125, 126,  13, 127, 128, 129],\n",
       "       [  0,   0,   0,  53,  14,  54,  16,  19,  55,  12,   9,  34,  56,\n",
       "         57,  58,  59,  60,  40,  35,  61,  62,  63,  64,  65]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 24, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 24) (31, 2)\n",
      "(8, 24) (8, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6952 - accuracy: 0.3548\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6804 - accuracy: 0.8387\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6651 - accuracy: 0.8065\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6422 - accuracy: 0.8065\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6110 - accuracy: 0.8065\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5639 - accuracy: 0.8065\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4876 - accuracy: 0.8065\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4020 - accuracy: 0.8065\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4102 - accuracy: 0.8065\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.3820 - accuracy: 0.8065\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3325 - accuracy: 0.8065\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2875 - accuracy: 0.8065\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2938 - accuracy: 0.8065\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2686 - accuracy: 0.8387\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2346 - accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62cc2d5a58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "data_majority = data[data['sentiment'] == 'negative']\n",
    "data_minority = data[data['sentiment'] == 'positive']\n",
    "\n",
    "bias = data_minority.shape[0]/data_majority.shape[0]\n",
    "# lets split train/test data first then \n",
    "train = pd.concat([data_majority.sample(frac=0.8,random_state=200),\n",
    "         data_minority.sample(frac=0.8,random_state=200)])\n",
    "test = pd.concat([data_majority.drop(data_majority.sample(frac=0.8,random_state=200).index),\n",
    "        data_minority.drop(data_minority.sample(frac=0.8,random_state=200).index)])\n",
    "\n",
    "train = shuffle(train)\n",
    "test = shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive data in training: 25\n",
      "negative data in training: 6\n",
      "positive data in test: 6\n",
      "negative data in test: 2\n"
     ]
    }
   ],
   "source": [
    "print('positive data in training:',(train.sentiment == 'positive').sum())\n",
    "print('negative data in training:',(train.sentiment == 'negative').sum())\n",
    "print('positive data in test:',(test.sentiment == 'positive').sum())\n",
    "print('negative data in test:',(test.sentiment == 'negative').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class before upsample: (6, 2)\n",
      "minority class before upsample: (25, 2)\n",
      "After upsampling\n",
      "positive    6\n",
      "negative    6\n",
      "Name: sentiment, dtype: int64\n",
      "x_train shape: (12, 29)\n",
      "x_test shape (8, 29)\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes in training data for upsampling \n",
    "data_majority = train[train['sentiment'] == 'negative']\n",
    "data_minority = train[train['sentiment'] == 'positive']\n",
    "\n",
    "print(\"majority class before upsample:\",data_majority.shape)\n",
    "print(\"minority class before upsample:\",data_minority.shape)\n",
    "\n",
    "# Upsample minority class\n",
    "data_minority_upsampled = resample(data_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples= data_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"After upsampling\\n\",data_upsampled.sentiment.value_counts(),sep = \"\")\n",
    "\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values) # training with whole data\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_upsampled['text'].values)\n",
    "X_train = pad_sequences(X_train,maxlen=29)\n",
    "Y_train = pd.get_dummies(data_upsampled['sentiment']).values\n",
    "print('x_train shape:',X_train.shape)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test['text'].values)\n",
    "X_test = pad_sequences(X_test,maxlen=29)\n",
    "Y_test = pd.get_dummies(test['sentiment']).values\n",
    "print(\"x_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 29, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 192)               246528    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 386       \n",
      "=================================================================\n",
      "Total params: 502,914\n",
      "Trainable params: 502,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "embed_dim = 128\n",
    "lstm_out = 192\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4879 - accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4813 - accuracy: 0.6667\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4706 - accuracy: 0.5000\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4619 - accuracy: 0.5000\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4480 - accuracy: 0.5000\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4352 - accuracy: 0.5000\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4039 - accuracy: 0.5000\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3654 - accuracy: 0.5000\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3607 - accuracy: 0.5000\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3485 - accuracy: 0.5000\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2963 - accuracy: 0.5833\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2584 - accuracy: 0.6667\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2293 - accuracy: 0.6667\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1750 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1268 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62c6f68908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# also adding weights\n",
    "class_weights = {0: 1 ,\n",
    "                1: 1.6/bias }\n",
    "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 312 110   3 158  11 291]]\n",
      "1/1 - 0s\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "twt = ['I love this movie and music was best of all']\n",
    "#vectorizing the sentence by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the sentence to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
